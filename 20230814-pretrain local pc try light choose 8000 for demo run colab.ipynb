{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CGproject-record/Heartbeat_Classification_try/blob/main/20230814-pretrain%20local%20pc%20try%20light%20choose%208000%20for%20demo%20run%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a568207",
      "metadata": {
        "id": "8a568207"
      },
      "outputs": [],
      "source": [
        "# 20230803-pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "499abcf1",
      "metadata": {
        "id": "499abcf1",
        "outputId": "2a9010c9-daf2-4243-e2a3-ada6de6c6475"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n",
        "    y_true = K.cast(y_true, y_pred.dtype)\n",
        "\n",
        "    y_pred = K.one_hot(K.argmax(y_pred, axis=-1), num_classes=4)\n",
        "\n",
        "    tp = K.sum(y_true * y_pred, axis=0)\n",
        "    tn = K.sum((1 - y_true) * (1 - y_pred), axis=0)\n",
        "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
        "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    return K.mean(2 * precision * recall / (precision + recall + K.epsilon()))\n",
        "\n",
        "\n",
        "def categorical_focal_loss(gamma=2):\n",
        "    \"\"\"\n",
        "        Categorical form of focal loss.\n",
        "            FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
        "        References:\n",
        "            https://arxiv.org/pdf/1708.02002.pdf\n",
        "        Usage:\n",
        "            model.compile(loss=categorical_focal_loss(gamma=2), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "            model.fit(class_weight={0:alpha0, 1:alpha1, ...}, ...)\n",
        "        Notes:\n",
        "           1. The alpha variable is the class_weight of keras.fit, so in implementation of the focal loss function\n",
        "           we needn't define this variable.\n",
        "           2. (important!!!) The output of the loss is the loss value of each training sample, not the total or average\n",
        "            loss of each batch.\n",
        "    \"\"\"\n",
        "\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n",
        "        y_true = K.cast(y_true, y_pred.dtype)\n",
        "\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "\n",
        "        return K.sum(-y_true * K.pow(1 - y_pred, gamma) * K.log(y_pred), axis=-1)\n",
        "\n",
        "    return focal_loss\n",
        "\n",
        "\n",
        "def load_data(filename=\"./mitdb_light_8000.pkl\"):\n",
        "    import pickle\n",
        "\n",
        "    with open(filename, \"rb\") as f:\n",
        "        (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = pickle.load(f)\n",
        "\n",
        "    return (x1_train, x2_train, y_train), (x1_test, x2_test, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca496415",
      "metadata": {
        "id": "ca496415",
        "outputId": "600e6188-b111-42f5-e3eb-b0373a0b88b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\users\\pek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From c:\\users\\pek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\users\\pek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From c:\\users\\pek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 200, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 64, 16)       192         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 16)       64          conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 16)       0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 31, 16)       0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 27, 32)       2592        max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 27, 32)       128         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 27, 32)       0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 13, 32)       0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 11, 64)       6208        max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 11, 64)       256         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 11, 64)       0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 5, 64)        0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 320)          0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 324)          0           flatten_1[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           20800       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            260         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 30,500\n",
            "Trainable params: 30,276\n",
            "Non-trainable params: 224\n",
            "__________________________________________________________________________________________________\n",
            "training:\n",
            "8000/8000 [==============================] - 0s 24us/step\n",
            "[[7417    1    0    0]\n",
            " [   2    5    0    0]\n",
            " [   2    1  568    0]\n",
            " [   4    0    0    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.999     1.000     0.999      7418\n",
            "           1      0.714     0.714     0.714         7\n",
            "           2      1.000     0.995     0.997       571\n",
            "           3      0.000     0.000     0.000         4\n",
            "\n",
            "    accuracy                          0.999      8000\n",
            "   macro avg      0.678     0.677     0.678      8000\n",
            "weighted avg      0.998     0.999     0.998      8000\n",
            "\n",
            "testing:\n",
            "8000/8000 [==============================] - 0s 12us/step\n",
            "[[7825    0   79   18]\n",
            " [  19   16    0    0]\n",
            " [   0    1   42    0]\n",
            " [   0    0    0    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.998     0.988     0.993      7922\n",
            "           1      0.941     0.457     0.615        35\n",
            "           2      0.347     0.977     0.512        43\n",
            "           3      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.985      8000\n",
            "   macro avg      0.571     0.605     0.530      8000\n",
            "weighted avg      0.994     0.985     0.988      8000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\users\\pek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\users\\pek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = load_data()\n",
        "\n",
        "    x1_train = np.expand_dims(x1_train, axis=-1)\n",
        "    x1_test = np.expand_dims(x1_test, axis=-1)\n",
        "\n",
        "    scaler = RobustScaler()\n",
        "    x2_train = scaler.fit_transform(x2_train)\n",
        "    x2_test = scaler.transform(x2_test)\n",
        "\n",
        "    model = load_model(os.path.join(\"./models\", \"model_focalloss.h5\"),\n",
        "                       custom_objects={\"focal_loss\": categorical_focal_loss(gamma=2),\n",
        "                                       \"f1\": f1})\n",
        "    model.summary()\n",
        "\n",
        "    print(\"training:\")\n",
        "    y_true, y_pred = y_train, np.argmax(model.predict([x1_train, x2_train], batch_size=1024, verbose=1), axis=-1)\n",
        "\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, digits=3))\n",
        "\n",
        "    print(\"testing:\")\n",
        "    y_true, y_pred = y_test, np.argmax(model.predict([x1_test, x2_test], batch_size=1024, verbose=1), axis=-1)\n",
        "\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, digits=3))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}