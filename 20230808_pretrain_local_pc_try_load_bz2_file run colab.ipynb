{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CGproject-record/Heartbeat_Classification_try/blob/main/20230808_pretrain_local_pc_try_load_bz2_file%20run%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a568207",
      "metadata": {
        "id": "8a568207"
      },
      "outputs": [],
      "source": [
        "# 20230803-pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "499abcf1",
      "metadata": {
        "id": "499abcf1",
        "outputId": "0da29db7-e060-47d8-bb1a-88d86fb4979d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-09e9c540fb12>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mx1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-09e9c540fb12>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/bz2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://github.com/CGproject-record/Heartbeat_Classification_try/raw/main/mitdb.pkl.bz2'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import gzip\n",
        "import bz2\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n",
        "    y_true = K.cast(y_true, y_pred.dtype)\n",
        "\n",
        "    y_pred = K.one_hot(K.argmax(y_pred, axis=-1), num_classes=4)\n",
        "\n",
        "    tp = K.sum(y_true * y_pred, axis=0)\n",
        "    tn = K.sum((1 - y_true) * (1 - y_pred), axis=0)\n",
        "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
        "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    return K.mean(2 * precision * recall / (precision + recall + K.epsilon()))\n",
        "\n",
        "\n",
        "def categorical_focal_loss(gamma=2):\n",
        "    \"\"\"\n",
        "        Categorical form of focal loss.\n",
        "            FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
        "        References:\n",
        "            https://arxiv.org/pdf/1708.02002.pdf\n",
        "        Usage:\n",
        "            model.compile(loss=categorical_focal_loss(gamma=2), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "            model.fit(class_weight={0:alpha0, 1:alpha1, ...}, ...)\n",
        "        Notes:\n",
        "           1. The alpha variable is the class_weight of keras.fit, so in implementation of the focal loss function\n",
        "           we needn't define this variable.\n",
        "           2. (important!!!) The output of the loss is the loss value of each training sample, not the total or average\n",
        "            loss of each batch.\n",
        "    \"\"\"\n",
        "\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n",
        "        y_true = K.cast(y_true, y_pred.dtype)\n",
        "\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "\n",
        "        return K.sum(-y_true * K.pow(1 - y_pred, gamma) * K.log(y_pred), axis=-1)\n",
        "\n",
        "    return focal_loss\n",
        "\n",
        "# original\n",
        "# def load_data(filename=\"./dataset/mitdb.pkl\"):\n",
        "#     import pickle\n",
        "\n",
        "#     with open(filename, \"rb\") as f:\n",
        "#         (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = pickle.load(f)\n",
        "\n",
        "#     return (x1_train, x2_train, y_train), (x1_test, x2_test, y_test)\n",
        "\n",
        "# .gz\n",
        "# def load_data(filename=\"./dataset/mitdb.pkl.gz\"):\n",
        "#     import pickle\n",
        "\n",
        "#     with gzip.open(filename, \"rb\") as f:\n",
        "#         (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = pickle.load(f)\n",
        "\n",
        "#     return (x1_train, x2_train, y_train), (x1_test, x2_test, y_test)\n",
        "\n",
        "\n",
        "#  data = bz2.BZ2File(file, ‘rb’)\n",
        "# bz2\n",
        "def load_data(filename=\"https://github.com/CGproject-record/Heartbeat_Classification_try/raw/main/mitdb.pkl.bz2\"):\n",
        "    import pickle\n",
        "\n",
        "    with bz2.BZ2File(filename, \"rb\") as f:\n",
        "        (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = pickle.load(f)\n",
        "\n",
        "    return (x1_train, x2_train, y_train), (x1_test, x2_test, y_test)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = load_data()\n",
        "\n",
        "    x1_train = np.expand_dims(x1_train, axis=-1)\n",
        "    x1_test = np.expand_dims(x1_test, axis=-1)\n",
        "\n",
        "    scaler = RobustScaler()\n",
        "    x2_train = scaler.fit_transform(x2_train)\n",
        "    x2_test = scaler.transform(x2_test)\n",
        "\n",
        "    model = load_model(os.path.join(\"\", \"https://github.com/CGproject-record/Heartbeat_Classification_try/raw/main/model_focalloss.h5\"),\n",
        "                       custom_objects={\"focal_loss\": categorical_focal_loss(gamma=2),\n",
        "                                       \"f1\": f1})\n",
        "    model.summary()\n",
        "\n",
        "    print(\"training:\")\n",
        "    y_true, y_pred = y_train, np.argmax(model.predict([x1_train, x2_train], batch_size=1024, verbose=1), axis=-1)\n",
        "\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, digits=3))\n",
        "\n",
        "    print(\"testing:\")\n",
        "    y_true, y_pred = y_test, np.argmax(model.predict([x1_test, x2_test], batch_size=1024, verbose=1), axis=-1)\n",
        "\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91424e5",
      "metadata": {
        "id": "f91424e5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}