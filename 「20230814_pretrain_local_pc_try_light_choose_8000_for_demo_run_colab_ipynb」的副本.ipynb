{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a568207",
      "metadata": {
        "id": "8a568207"
      },
      "outputs": [],
      "source": [
        "# 20230803-pretrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "# 獲取授權碼之後輸入即可連動雲端硬碟\n"
      ],
      "metadata": {
        "id": "BBNeIdiI20_D",
        "outputId": "6f082a14-a6c9-43b0-8d6d-631fc2014733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BBNeIdiI20_D",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 從github 下載 mitdb_light_8000.pkl model_focalloss.h5  上傳至執行者之google drive資料夾 改路徑 即可執行"
      ],
      "metadata": {
        "id": "ixype0q74FLv"
      },
      "id": "ixype0q74FLv",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "499abcf1",
      "metadata": {
        "id": "499abcf1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n",
        "    y_true = K.cast(y_true, y_pred.dtype)\n",
        "\n",
        "    y_pred = K.one_hot(K.argmax(y_pred, axis=-1), num_classes=4)\n",
        "\n",
        "    tp = K.sum(y_true * y_pred, axis=0)\n",
        "    tn = K.sum((1 - y_true) * (1 - y_pred), axis=0)\n",
        "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
        "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    return K.mean(2 * precision * recall / (precision + recall + K.epsilon()))\n",
        "\n",
        "\n",
        "def categorical_focal_loss(gamma=2):\n",
        "    \"\"\"\n",
        "        Categorical form of focal loss.\n",
        "            FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
        "        References:\n",
        "            https://arxiv.org/pdf/1708.02002.pdf\n",
        "        Usage:\n",
        "            model.compile(loss=categorical_focal_loss(gamma=2), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "            model.fit(class_weight={0:alpha0, 1:alpha1, ...}, ...)\n",
        "        Notes:\n",
        "           1. The alpha variable is the class_weight of keras.fit, so in implementation of the focal loss function\n",
        "           we needn't define this variable.\n",
        "           2. (important!!!) The output of the loss is the loss value of each training sample, not the total or average\n",
        "            loss of each batch.\n",
        "    \"\"\"\n",
        "\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n",
        "        y_true = K.cast(y_true, y_pred.dtype)\n",
        "\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "\n",
        "        return K.sum(-y_true * K.pow(1 - y_pred, gamma) * K.log(y_pred), axis=-1)\n",
        "\n",
        "    return focal_loss\n",
        "\n",
        "# 需自行修改檔案位置\n",
        "def load_data(filename=\"/content/gdrive/My Drive/Colab Notebooks/mitdb_light_8000.pkl\"):\n",
        "    import pickle\n",
        "\n",
        "    with open(filename, \"rb\") as f:\n",
        "        (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = pickle.load(f)\n",
        "\n",
        "    return (x1_train, x2_train, y_train), (x1_test, x2_test, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ca496415",
      "metadata": {
        "id": "ca496415",
        "outputId": "0bbdb6a0-846f-44a5-8a0e-8c60703e2c69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 64, 16)       192         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 64, 16)      64          ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 16)       0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 31, 16)      0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 27, 32)       2592        ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 27, 32)      128         ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 27, 32)       0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 13, 32)      0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 11, 64)       6208        ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 11, 64)      256         ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 11, 64)       0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 5, 64)       0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 320)          0           ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 324)          0           ['flatten_1[0][0]',              \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           20800       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            260         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 30,500\n",
            "Trainable params: 30,276\n",
            "Non-trainable params: 224\n",
            "__________________________________________________________________________________________________\n",
            "training:\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "[[7417    1    0    0]\n",
            " [   2    5    0    0]\n",
            " [   2    1  568    0]\n",
            " [   4    0    0    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.999     1.000     0.999      7418\n",
            "           1      0.714     0.714     0.714         7\n",
            "           2      1.000     0.995     0.997       571\n",
            "           3      0.000     0.000     0.000         4\n",
            "\n",
            "    accuracy                          0.999      8000\n",
            "   macro avg      0.678     0.677     0.678      8000\n",
            "weighted avg      0.998     0.999     0.998      8000\n",
            "\n",
            "testing:\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "[[7825    0   79   18]\n",
            " [  19   16    0    0]\n",
            " [   0    1   42    0]\n",
            " [   0    0    0    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.998     0.988     0.993      7922\n",
            "           1      0.941     0.457     0.615        35\n",
            "           2      0.347     0.977     0.512        43\n",
            "           3      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.985      8000\n",
            "   macro avg      0.571     0.605     0.530      8000\n",
            "weighted avg      0.994     0.985     0.988      8000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (x1_train, x2_train, y_train), (x1_test, x2_test, y_test) = load_data()\n",
        "\n",
        "    x1_train = np.expand_dims(x1_train, axis=-1)\n",
        "    x1_test = np.expand_dims(x1_test, axis=-1)\n",
        "\n",
        "    scaler = RobustScaler()\n",
        "    x2_train = scaler.fit_transform(x2_train)\n",
        "    x2_test = scaler.transform(x2_test)\n",
        "# 需自行修改檔案位置\n",
        "    model = load_model(os.path.join(\"/content/gdrive/My Drive/Colab Notebooks/\", \"model_focalloss.h5\"),\n",
        "                       custom_objects={\"focal_loss\": categorical_focal_loss(gamma=2),\n",
        "                                       \"f1\": f1})\n",
        "    model.summary()\n",
        "\n",
        "    print(\"training:\")\n",
        "    y_true, y_pred = y_train, np.argmax(model.predict([x1_train, x2_train], batch_size=1024, verbose=1), axis=-1)\n",
        "\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, digits=3))\n",
        "\n",
        "    print(\"testing:\")\n",
        "    y_true, y_pred = y_test, np.argmax(model.predict([x1_test, x2_test], batch_size=1024, verbose=1), axis=-1)\n",
        "\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred, digits=3))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}